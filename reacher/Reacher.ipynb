{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reacher with obstacle avoidance\n",
    "\n",
    "This is the code to train the reaching armature affordance model with an overhead camera as sensor input. For more detail about the motivation behind network architecture choices and the training procedure, check out the  Hexapod notebook in the other directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "from math import *\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pybullet as p\n",
    "\n",
    "import copy\n",
    "\n",
    "def tovar(x):\n",
    "    return Variable(torch.FloatTensor(x).cuda(), requires_grad = False)\n",
    "\n",
    "def toivar(x):\n",
    "    return Variable(torch.LongTensor(x).cuda(), requires_grad = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "This class contains code to instantiate and simulate the reaching armature and its sensor inputs in pybullet. We'll mostly use this to generate a large static dataset for training, and for testing the final trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Simulation():\n",
    "    def __init__(self, angles, objs = [], gui=False):\n",
    "        if gui:\n",
    "            self.pid = p.connect(p.GUI)\n",
    "        else:\n",
    "            self.pid = p.connect(p.DIRECT)\n",
    "        \n",
    "        pid = self.pid        \n",
    "        self.view = p.computeViewMatrix([0,0,25], [0,0,0], [0,1,0])\n",
    "        self.proj = p.computeProjectionMatrixFOV(60, 1.0, 0.5, 25.0)\n",
    "        \n",
    "        planeId = p.loadURDF(\"plane.urdf\", physicsClientId=pid)\n",
    "        p.createConstraint(planeId,-1,-1,-1,p.JOINT_FIXED,\\\n",
    "                           [0,0,1],[0,0,0],[0,0,0],physicsClientId=pid)\n",
    "        \n",
    "        for i in range(len(objs)):\n",
    "            obj = p.loadURDF(objs[i][0], objs[i][1], physicsClientId=pid)\n",
    "            p.createConstraint(obj,-1,-1,-1,p.JOINT_FIXED,\\\n",
    "                              [0,0,1],[0,0,0],objs[i][1],physicsClientId=pid)\n",
    "            \n",
    "        cubeStartPos = [0,0,0]\n",
    "        cubeStartOrientation = p.getQuaternionFromEuler([0,0,0])\n",
    "        self.boxId = p.loadURDF(\"arm.urdf\", cubeStartPos, cubeStartOrientation, physicsClientId=pid)\n",
    "        p.createConstraint(self.boxId,-1,-1,-1,p.JOINT_FIXED,\\\n",
    "                           [0,0,1],[0,0,0],[0,0,0],physicsClientId=pid)\n",
    "    \n",
    "        links = np.arange(8)\n",
    "        forces = [8000 for x in np.arange(8)]\n",
    "        vels = [0 for x in np.arange(8)]\n",
    "        pgain = [0.2 for x in np.arange(8)]\n",
    "        vgain = [0.6 for x in np.arange(8)]\n",
    "        p.setJointMotorControlArray(self.boxId, links, p.POSITION_CONTROL, \\\n",
    "                                    targetPositions = angles, \\\n",
    "                                    forces = forces, \\\n",
    "                                    targetVelocities = vels, \\\n",
    "                                    positionGains = pgain, \\\n",
    "                                    velocityGains = vgain, \\\n",
    "                                    physicsClientId=pid)\n",
    "\n",
    "        for i in range(10):\n",
    "            p.stepSimulation(physicsClientId=pid)\n",
    "\n",
    "    def getState(self):\n",
    "        state = []\n",
    "        boxId = self.boxId\n",
    "        pid = self.pid\n",
    "        \n",
    "        for i in range(8):\n",
    "            lstate = p.getLinkState(boxId,i,physicsClientId=pid)\n",
    "            state.append(lstate[0][0])\n",
    "            state.append(lstate[0][1])\n",
    "            state.append(lstate[0][2])\n",
    "            \n",
    "        return np.array(state)\n",
    "    \n",
    "    def getInState(self):\n",
    "        camera = p.getCameraImage(width=24, height=24, \\\n",
    "                                  viewMatrix=self.view, projectionMatrix=self.proj, \\\n",
    "                                  renderer = p.ER_TINY_RENDERER, physicsClientId=self.pid)\n",
    "        \n",
    "        state = np.array(camera[3])\n",
    "        return state.ravel()\n",
    "\n",
    "    def simulateActions(self,acts,delay=0):\n",
    "        boxId = self.boxId\n",
    "        pid = self.pid\n",
    "        links = np.arange(8)\n",
    "        forces = [8000 for x in np.arange(8)]\n",
    "        vels = [0 for x in np.arange(8)]\n",
    "        pgain = [0.2 for x in np.arange(8)]\n",
    "        vgain = [0.6 for x in np.arange(8)]\n",
    "        \n",
    "        states = []\n",
    "                \n",
    "        for j in range(200):\n",
    "            if delay:\n",
    "                time.sleep(delay)\n",
    "\n",
    "            p.setJointMotorControlArray(boxId, links, p.POSITION_CONTROL, \\\n",
    "                                        targetPositions = acts, \\\n",
    "                                        forces=forces, \\\n",
    "                                        targetVelocities = vels, \\\n",
    "                                        positionGains = pgain, \\\n",
    "                                        velocityGains = vgain, \\\n",
    "                                        physicsClientId=pid)\n",
    "\n",
    "            p.stepSimulation(physicsClientId=pid)\n",
    "        \n",
    "        states = self.getState()\n",
    "    \n",
    "        return np.array(states)\n",
    "    \n",
    "    def stop(self):\n",
    "        p.disconnect(self.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for generating environments and training data\n",
    "\n",
    "def simulate(x):\n",
    "    s = Simulation(np.zeros(8),objs=x[1])\n",
    "    a = s.simulateActions(x[0])\n",
    "    s.stop()\n",
    "    return a\n",
    "\n",
    "def getSimsStates(BS=10):\n",
    "    olist = []\n",
    "    states = []\n",
    "    for i in range(BS):\n",
    "        nobj = np.random.randint(6)\n",
    "        objlist = []\n",
    "        for j in range(nobj):            \n",
    "            if np.random.randint(2)==0:\n",
    "                otype=\"cube.urdf\"\n",
    "            else:\n",
    "                otype=\"sphere.urdf\"\n",
    "            \n",
    "            pos = [np.random.rand()*10-5, np.random.rand()*10-5, np.random.rand()*5+2]\n",
    "            \n",
    "            while (pos[0]**2+pos[1]**2 < 4.5*4.5):\n",
    "                pos = [np.random.rand()*10-5, np.random.rand()*10-5, np.random.rand()*5+2]\n",
    "                \n",
    "            objlist.append([otype, pos])\n",
    "        olist.append(objlist)\n",
    "        s = Simulation(np.zeros(8),objs=objlist)\n",
    "        states.append(s.getInState())\n",
    "        s.stop()\n",
    "    \n",
    "    states = np.array(states)\n",
    "    \n",
    "    return states, olist\n",
    "\n",
    "def getData(N):\n",
    "    MESH = 7\n",
    "    PROPOSALS = MESH*MESH\n",
    "    states, olist = getSimsStates(BS=N)\n",
    "    acts = []\n",
    "    ends = []\n",
    "    \n",
    "    a,p = propose.generate(tovar(states), predict)    \n",
    "    a = a.cpu().data.numpy()\n",
    "    \n",
    "    for i in range(N):\n",
    "        acts.append(np.clip(1.0*(np.random.rand(ACTUATORS)*2-1),-1,1))\n",
    "    ends = []\n",
    "    \n",
    "    pool = Pool(4)\n",
    "    ends = pool.map(simulate, zip(acts,olist))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    ends = np.array(ends)\n",
    "    \n",
    "    return states, np.array(acts), ends\n",
    "\n",
    "def getProposeData(N):\n",
    "    MESH = 7\n",
    "    PROPOSALS = MESH*MESH\n",
    "    states, olist = getSimsStates(BS=N)\n",
    "    acts = []\n",
    "    ends = []\n",
    "    \n",
    "    a,p = propose.generate(tovar(states), predict)    \n",
    "    a = a.cpu().data.numpy()\n",
    "    \n",
    "    for i in range(N):\n",
    "        acts.append(np.clip(a[i,:,i%PROPOSALS] + 0.1*(np.random.rand(ACTUATORS)*2-1),-1,1))\n",
    "    ends = []\n",
    "    \n",
    "    pool = Pool(4)\n",
    "    ends = pool.map(simulate, zip(acts,olist))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    ends = np.array(ends)\n",
    "    \n",
    "    return states, np.array(acts), ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor network\n",
    "\n",
    "We first process the sensor inputs through three dense layers, and then merge in the actuator values. This lets the proposal network take advantage of the visual system learned by the predictor to understand the environment, which helps the proposer learn to make use of camera data quickly.\n",
    "\n",
    "We use a dense architecture for the camera here because it's low enough resolution to permit it, but it would be straightforward to switch to a convolutional network to handle higher resolutions. Note that the Conv1d layers here aren't actually convolutions but are rather just a shorthand to make it easy to processing multiple sets of proposed actions in parallel later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SENSORS = 24*24\n",
    "OSENSORS = 3*8\n",
    "HIDDEN = 512\n",
    "HIDDEN2 = 128\n",
    "ACTUATORS = 8\n",
    "MESH = 7\n",
    "\n",
    "# Measures prediction error\n",
    "def wDist(x,y):\n",
    "    return (x-y)**2\n",
    "\n",
    "# Measures outcome distance\n",
    "# 7*3 is the offset associated with the segment at the end of the arm,\n",
    "# so the outcome distance only cares about tip position\n",
    "def wDist4(x,y):\n",
    "    return (x[:,7*3:7*3+3,:,:]-y[:,7*3:7*3+3,:,:])**2\n",
    "\n",
    "class Predict(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Predict,self).__init__()\n",
    "        \n",
    "        # \n",
    "        self.p1 = nn.Conv1d(SENSORS, HIDDEN, 1).cuda()\n",
    "        self.p2 = nn.Conv1d(HIDDEN, HIDDEN, 1).cuda()\n",
    "        self.p3 = nn.Conv1d(HIDDEN, HIDDEN, 1).cuda()\n",
    "        self.p4 = nn.Conv1d(HIDDEN+ACTUATORS, HIDDEN, 1).cuda()\n",
    "        self.p5 = nn.Conv1d(HIDDEN, HIDDEN, 1).cuda()\n",
    "        self.p6 = nn.Conv1d(HIDDEN, HIDDEN, 1).cuda()\n",
    "        self.p7 = nn.Conv1d(HIDDEN, HIDDEN, 1).cuda()\n",
    "        self.p8 = nn.Conv1d(HIDDEN, OSENSORS, 1).cuda()\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.adam = torch.optim.Adam(self.parameters(), lr = 2.5e-4)\n",
    "    \n",
    "    def process(self,state):\n",
    "        pz = F.elu(self.p1(1.0-state))\n",
    "        \n",
    "        return pz\n",
    "    \n",
    "    def predict_hid(self,z,a):\n",
    "        pz = z + F.elu(self.p3(F.elu(self.p2(z))))\n",
    "        pz = torch.cat([pz,a],1)\n",
    "        pz = F.elu(self.p5(F.elu(self.p4(pz))))\n",
    "        pz = pz + F.elu(self.p7(F.elu(self.p6(pz))))\n",
    "        \n",
    "        pzpred = self.p8(pz)\n",
    "        \n",
    "        return pzpred\n",
    "    \n",
    "    # The depth camera tends to have values near 1.0, with objects being lower,\n",
    "    # so 1-x is a convenient transform to normalize this a bit\n",
    "    def predict(self,state,a):\n",
    "        pz = self.drop(F.elu(self.p1(1.0-state)))\n",
    "        pz = pz + self.drop(F.elu(self.p3(self.drop(F.elu(self.p2(pz))))))\n",
    "        pz = torch.cat([pz,a],1)\n",
    "        pz = self.drop(F.elu(self.p5(self.drop(F.elu(self.p4(pz))))))\n",
    "        pz = pz + self.drop(F.elu(self.p7(self.drop(F.elu(self.p6(pz))))))\n",
    "        \n",
    "        pzpred = self.p8(pz)\n",
    "        \n",
    "        return pzpred\n",
    "\n",
    "    def predloss(self,y,p):\n",
    "        return torch.mean(wDist(y,p)) #torch.mean(psig*wDist(y,p)) - 0.5*torch.mean(torch.log(psig)), \n",
    "\n",
    "# Test the predictor on a hold-out set to check for overfitting\n",
    "def testPredictData(states,acts,ends):\n",
    "    BS = 200\n",
    "    predict.eval()\n",
    "    err = 0\n",
    "    count = 0\n",
    "    idx = np.random.permutation(states.shape[0])\n",
    "    \n",
    "    for i in range(states.shape[0]//BS):\n",
    "        s = tovar(states[idx[i*BS:i*BS+BS]])\n",
    "        a = tovar(acts[idx[i*BS:i*BS+BS]])\n",
    "        e = tovar(ends[idx[i*BS:i*BS+BS]])\n",
    "\n",
    "        preds = predict.predict(s.unsqueeze(2),a.unsqueeze(2)).squeeze(2)\n",
    "        loss = predict.predloss(e, preds) \n",
    "        \n",
    "        err = err + loss.cpu().data.numpy()[0] \n",
    "        count += 1\n",
    "    \n",
    "    return err/float(count)\n",
    "\n",
    "# Train the predictor for one epoch on the dataset \n",
    "def trainPredictData(states,acts,ends):\n",
    "    BS = 50\n",
    "    predict.train()\n",
    "    err = 0\n",
    "    count = 0\n",
    "    idx = np.random.permutation(states.shape[0])\n",
    "    \n",
    "    for i in range(states.shape[0]//BS):\n",
    "        s = tovar(states[idx[i*BS:i*BS+BS]])\n",
    "        a = tovar(acts[idx[i*BS:i*BS+BS]])\n",
    "        e = tovar(ends[idx[i*BS:i*BS+BS]])\n",
    "\n",
    "        predict.zero_grad()\n",
    "        preds = predict.predict(s.unsqueeze(2),a.unsqueeze(2)).squeeze(2)\n",
    "        loss = predict.predloss(e, preds) \n",
    "        \n",
    "        loss.backward()\n",
    "        predict.adam.step()\n",
    "        \n",
    "        err = err + loss.cpu().data.numpy()[0] \n",
    "        count += 1\n",
    "    \n",
    "    return err/float(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposer network\n",
    "\n",
    "We borrow the first layer from the predictor to help the proposer interpret the environment. That layer is held constant while training the proposer, so it's just a kind of learned pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Propose(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Propose,self).__init__()\n",
    "        \n",
    "        self.d1 = nn.Conv1d(2+HIDDEN, HIDDEN2, 1).cuda()\n",
    "        self.d2 = nn.Conv1d(HIDDEN2, HIDDEN2, 1).cuda()\n",
    "        self.d3 = nn.Conv1d(HIDDEN2, HIDDEN2, 1).cuda()\n",
    "        self.d4 = nn.Conv1d(HIDDEN2, HIDDEN2, 1).cuda()\n",
    "        self.d5 = nn.Conv1d(HIDDEN2, HIDDEN2, 1).cuda()\n",
    "        self.d6 = nn.Conv1d(HIDDEN2, HIDDEN2, 1).cuda()        \n",
    "        self.dprop = nn.Conv1d(HIDDEN2, ACTUATORS, 1).cuda()\n",
    "        \n",
    "        self.adam = torch.optim.Adam(self.parameters(), lr = 1e-5)\n",
    "            \n",
    "    def forward(self,idx):                \n",
    "        z = F.elu(self.d1(idx))\n",
    "        z = z+F.elu(self.d3(F.elu(self.d2(z))))\n",
    "        z = z+F.elu(self.d5(F.elu(self.d4(z))))\n",
    "        z = F.elu(self.d6(z))\n",
    "        \n",
    "        a = F.tanh(self.dprop(z))\n",
    "        return a\n",
    "    \n",
    "    def generate(self, state, pred):\n",
    "        pred.eval()\n",
    "        BS = state.size()[0]\n",
    "        xx,yy = np.meshgrid(np.arange(MESH)/float(MESH), \\\n",
    "                            np.arange(MESH)/float(MESH))\n",
    "        xx = xx.ravel()\n",
    "        yy = yy.ravel()\n",
    "        \n",
    "        idx_x = tovar(2.0*xx - 1.0).unsqueeze(0).unsqueeze(1).expand(BS,1,MESH*MESH)\n",
    "        idx_y = tovar(2.0*yy - 1.0).unsqueeze(0).unsqueeze(1).expand(BS,1,MESH*MESH)\n",
    "                \n",
    "        state = state.unsqueeze(2)\n",
    "        \n",
    "        # This uses the predictor network's first layer to process the sensory input\n",
    "        z = pred.process(state).expand(BS,HIDDEN,MESH*MESH)\n",
    "        \n",
    "        a = self.forward(torch.cat([z,idx_x,idx_y],1))\n",
    "        \n",
    "        ashp = a.size()\n",
    "        \n",
    "        a = a.view(ashp[0], ACTUATORS, MESH*MESH)\n",
    "        x = pred.predict_hid(z,a)\n",
    "        \n",
    "        return a,x\n",
    "\n",
    "def getProposals(states):\n",
    "    acts, preds = propose.generate(tovar(states), predict)    \n",
    "    \n",
    "    return acts, preds\n",
    "\n",
    "def measureMinDist(preds):\n",
    "    BS = preds.size()[0]\n",
    "    PROPOSALS = MESH*MESH\n",
    "    # Now train the proposal network on distance between generated outcomes\n",
    "    p1 = preds.unsqueeze(2).expand(BS,OSENSORS,PROPOSALS,PROPOSALS)\n",
    "    p2 = preds.unsqueeze(3).expand(BS,OSENSORS,PROPOSALS,PROPOSALS)\n",
    "    dp = torch.sum( wDist4(p1,p2), 1).squeeze(1)\n",
    "    eye = tovar(np.eye(PROPOSALS)).unsqueeze(0).expand_as(dp)\n",
    "    \n",
    "    dp = dp + 1e6*eye\n",
    "    mind,minidx = torch.min(dp,2)\n",
    "    mind,minidx = torch.min(mind,1)\n",
    "    loss2 = torch.mean(mind)\n",
    "    \n",
    "    return loss2\n",
    "\n",
    "def evalProposals(acts, olist):\n",
    "    outs = []\n",
    "    pool = Pool(4)\n",
    "    \n",
    "    for j in range(acts.shape[2]):\n",
    "        o = pool.map(simulate, zip([acts[i,:,j] for i in range(BS)], olist))\n",
    "        outs.append(o)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    outs = np.array(outs)\n",
    "    \n",
    "    return outs\n",
    "\n",
    "# Train the proposer for some number of epochs\n",
    "def trainPropose(epochs):\n",
    "    global MESH\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.permutation(states.shape[0])\n",
    "\n",
    "        err2 = 0\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(states.shape[0]//BS):\n",
    "            propose.zero_grad()\n",
    "\n",
    "            pacts, preds = getProposals(states[idx[i*BS:i*BS+BS]])\n",
    "\n",
    "            pgrid = preds.view((BS,OSENSORS,MESH,MESH))\n",
    "            delta = torch.mean((pgrid[:,:,:-1,:] - pgrid[:,:,1:,:])**2) + torch.mean((pgrid[:,:,:,:-1] - pgrid[:,:,:,1:])**2)\n",
    "            loss2 = measureMinDist(preds)\n",
    "            loss = -loss2 + 0.1*delta\n",
    "            err2 += loss2.cpu().data.numpy()[0]\n",
    "            count += 1\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            propose.adam.step()\n",
    "        \n",
    "        # Log some training data\n",
    "        f = open(\"mindist_propose.txt\",\"a\")\n",
    "        f.write(\"%.6g\\n\" % (err2/float(count)))\n",
    "        f.close()\n",
    "\n",
    "        nm = MESH\n",
    "        MESH = 17\n",
    "        pacts, preds = getProposals(states[0:1])\n",
    "        preds = preds.cpu().data.numpy()[0]\n",
    "        np.savetxt(\"preds.txt\", preds[7*3:7*3+3,:].T)\n",
    "\n",
    "        MESH = nm\n",
    "        \n",
    "        # Save a checkpoint\n",
    "        torch.save(propose.state_dict(), open(\"propose.th\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the networks\n",
    "\n",
    "predict = Predict()\n",
    "propose = Propose()\n",
    "\n",
    "# To load from checkpoint, uncomment this\n",
    "#predict.load_state_dict(torch.load(\"predict.th\"))\n",
    "#propose.load_state_dict(torch.load(\"propose.th\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = np.zeros((0,SENSORS))\n",
    "acts = np.zeros((0,ACTUATORS))\n",
    "ends = np.zeros((0,OSENSORS))\n",
    "\n",
    "# If you've already generated the data, uncomment to load it in\n",
    "\n",
    "states = np.load(\"states.npy\")\n",
    "acts = np.load(\"acts.npy\")\n",
    "ends = np.load(\"ends.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data in chunks\n",
    "# Makes it easy to add variable amounts onto the existing dataset\n",
    "\n",
    "# This one generates random action playouts\n",
    "for i in range(1):\n",
    "    s, a, e = getData(N=500)\n",
    "    states = np.vstack([states,s])\n",
    "    acts = np.vstack([acts,a])\n",
    "    ends = np.vstack([ends,e])\n",
    "    \n",
    "np.save(\"states.npy\",states)\n",
    "np.save(\"acts.npy\",acts)\n",
    "np.save(\"ends.npy\",ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one generates playouts based on the current proposal network\n",
    "for i in range(1):\n",
    "    s, a, e = getProposeData(N=500)\n",
    "    states = np.vstack([states,s])\n",
    "    acts = np.vstack([acts,a])\n",
    "    ends = np.vstack([ends,e])\n",
    "    \n",
    "np.save(\"states.npy\",states)\n",
    "np.save(\"acts.npy\",acts)\n",
    "np.save(\"ends.npy\",ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train/test division\n",
    "idx = np.random.permutation(states.shape[0])\n",
    "\n",
    "test_states = states[idx[0:5000]]\n",
    "test_acts = acts[idx[0:5000]]\n",
    "test_ends = ends[idx[0:5000]]\n",
    "\n",
    "states = states[idx[5000:]]\n",
    "acts = acts[idx[5000:]]\n",
    "ends = ends[idx[5000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the predictor for 200 epochs\n",
    "\n",
    "for epoch in range(200):\n",
    "    lr = 2.5e-4\n",
    "    if epoch>100:\n",
    "        lr = 1e-4\n",
    "\n",
    "    for param_group in predict.adam.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    err = trainPredictData(states,acts,ends)\n",
    "    terr = testPredictData(test_states,test_acts,test_ends)\n",
    "    \n",
    "    # Log the training progress\n",
    "    f = open(\"error.txt\",\"a\")\n",
    "    f.write(\"%d %.6g %.6g\\n\" % (epoch,err,terr))\n",
    "    f.close()\n",
    "\n",
    "    # Save the model as we train\n",
    "    torch.save(predict.state_dict(), open(\"predict.th\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train proposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the proposer for 100 epochs\n",
    "\n",
    "BS = 100\n",
    "MESH = 9\n",
    "\n",
    "trainPropose(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
